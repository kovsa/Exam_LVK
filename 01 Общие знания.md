# **Компетенция 1.1. Общие знания по IP-сетям. Средний уровень**

*Администратор знает и понимает: стек протоколов TCP/IP; принципы организации IP-сетей IPv4 –  формирование, распределение IP-адресов; базовые принципы коммутации, маршрутизации в ЛВС; сегментирование ЛВС, протоколы канального, сетевого, транспортного и сеансового уровней модели ISO/OSI; основные принципы обеспечения отказоустойчивости сетевой инфраструктуры; основные принципы построения сетевой инфраструктуры для организации среды виртуализации*
#

Необходимо иметь общее представление [о модели OSI](https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D1%82%D0%B5%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_OSI): что это и зачем, сколько в ней уровней, уровни с 1 по 4 надо хорошо знать и понимать. Необходимо иметь представление какие протоколы работают на первых 4х уровнях ([ARP](https://ru.wikipedia.org/wiki/ARP), [Ethernet](https://ru.wikipedia.org/wiki/Ethernet), [IPv4](https://ru.wikipedia.org/wiki/IPv4), [TCP](https://ru.wikipedia.org/wiki/Transmission_Control_Protocol), [порты TCP](https://ru.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BF%D0%BE%D1%80%D1%82%D0%BE%D0%B2_TCP_%D0%B8_UDP), шлюз по умлчанию)\
Необходимо представлять зачем осуществляется [Сегментирование сети](https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D0%B3%D0%BC%D0%B5%D0%BD%D1%82_%D1%81%D0%B5%D1%82%D0%B8), что такое [домен коллизий](https://ru.wikipedia.org/wiki/%D0%94%D0%BE%D0%BC%D0%B5%D0%BD_%D0%BA%D0%BE%D0%BB%D0%BB%D0%B8%D0%B7%D0%B8%D0%B9), какому уровню модели OSI соответствует каждый сегмент сети и на каком уровне осуществляется связь этих сегментов, [маска сети](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%81%D0%BA%D0%B0_%D0%BF%D0%BE%D0%B4%D1%81%D0%B5%D1%82%D0%B8), [VLAN](https://ru.wikipedia.org/wiki/VLAN).\
Необходимо иметь общее представление о [петлях коммутации](http://xgu.ru/wiki/%D0%9F%D0%B5%D1%82%D0%BB%D1%8F_%D0%BA%D0%BE%D0%BC%D0%BC%D1%83%D1%82%D0%B0%D1%86%D0%B8%D0%B8) и предназначении протокола [STP](https://ru.wikipedia.org/wiki/STP).\
Необходимо знать про [агрегирование каналов](https://ru.wikipedia.org/wiki/%D0%90%D0%B3%D1%80%D0%B5%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%BA%D0%B0%D0%BD%D0%B0%D0%BB%D0%BE%D0%B2) для обеспечения отказоустойчивости, а также  про протоколы [EtherChannel](https://ru.wikipedia.org/wiki/EtherChannel), PortChannel и LACP.\
Надо понимать что такое [шлюз по умолчанию](https://ru.wikipedia.org/wiki/%D0%A8%D0%BB%D1%8E%D0%B7_%D0%BF%D0%BE_%D1%83%D0%BC%D0%BE%D0%BB%D1%87%D0%B0%D0%BD%D0%B8%D1%8E) и как обеспечивается его отказоустойчивость с помощью протокола [VRRP](https://ru.wikipedia.org/wiki/VRRP).\
Можно почитать серию статей на [Хабре](https://habr.com/ru/post/307252/).

## **МОДЕЛЬ OSI**
 ![Модель OSI/tcp/ip](https://user-images.githubusercontent.com/20071841/197455402-953c8efb-52c2-4948-910e-5a52d94f1df5.png)
**1. Физический уровень** (Physical Layer) - осуществляется передача битов по соответствующей среде (коаксиальный кабель, витая пара, оптволокно, беспроводная среда) через соответствующее оборудование.
  - Оборудование (сетевой адаптер, медиаконвертер, повторитель/концентратор)

**2. Канальный уровень** (Data Link Layer) - осуществляется доставка кадров (frame) между устройствами, подключенными к одному сетевому сегменту используя MAC-адреса. Заголовок Ethernet-кадра содержит аппаратные адреса (MAC-адреса (Media Access Control)) отправителя и получателя, что позволяет определить, какое устройство отправило кадр и какое устройство должно получить и обработать его.
  - Оборудование - Коммутатор

**3. Сетевой уровень** (Network Layer) - осуществляется маршрутизация трафика. На сетевом уровне работает протокол ARP (Address Resolution Protocol), который определяет соответствие между логическим адресом сетевого уровня (IP) и физическим адресом устройства (MAC). Здесь пересылаемая информация выступает уже в виде пакетов, состоящих из заголовка и поля данных.
Информация об известных IP и MAC-адресах хранится в виде таблицы (ARP-таблица) с данными, что позволяет устройствам не тратить время на повторную идентификацию.
  - Оборудование (маршрутизатор)

**4. Транспортный уровень** (Transport Layer) - осуществляется доставка данных с использованием различных протоколов (TCP (Transmission Control Protocol) и UDP (User Datagram Protocol)). Блоки данных делятся на отдельные фрагменты, размеры которых зависят от используемого протокола. При транспортировке данных, наиболее восприимчивых к потерям, например, web-страницы, задействуется протокол TCP с установлением соединения. Он контролирует целостность информации, в данном случае нашей страницы, ибо потеря какого-то контента заставит задуматься пользователя о его полезности. Чтобы сделать передачу более эффективной и быстрой, транспортный уровень разбивает данные на более мелкие сегменты. UDP-протокол используется с данными, для которых потери не так критичны, например, мультимедиа-трафик. Для них более заметна будет задержка, поэтому UDP обеспечивает связь без установки соединения. Во время передачи данных с помощью протокола UDP, пакеты делятся уже на автономные датаграммы. Они могут доставляться по разным маршрутам и в разной последовательности.

**5. Cеансовый уровень** (Session) - уровень модели OSI относится к «верхним». Здесь осуществляются операции с чистыми данными. Отвечает пятый уровень за поддержку связи во время сеанса или сессии. Он обеспечивает правильное взаимодействие между приложениями, позволяет синхронизировать разные задачи, обмениваться данными. Благодаря L5 происходит поддержка и завершение сеанса. Сеанс состоит из запросов и ответов, направляемых между разными приложениями. Сеансовый уровень используется в ПО, удаленно вызывающих процедуры. Примером работы L5 служит видеовызов в Skype или прямой эфир на широкую аудиторию. Во время сеанса нужно обеспечить синхронизованную передачу аудио и видео всем участникам конференции. За это и отвечают протоколы пятого уровня.

**6. Уровень представления данных** (Presentation) - Протоколы L6 осуществляют кодирование и декодирование информации. Информация, передаваемая по сети, на этом уровне не меняет своего содержания. Кроме перевода данных из одного формата в другой, L6 осуществляет и другие функции:
 - сжатие информации для увеличения пропускной способности канала;
 - шифрование данных для защиты от злоумышленников;
 - отправка запросов на прекращение сеанса связи.
Преобразование данных осуществляется автоматически и не требует от пользователя подтверждения. При получении данных с L5 автоматически устанавливаются стандартные форматы файлов.

**7. Прикладной уровень** (Application)- уровень приложений. Jтвечает за взаимодействие пользовательских приложений с работающей сетью. Этот уровень обеспечивает использование программами сетевых служб, отправку e-mail, обмен данными через торренты, предоставление ПО информации о сбоях и т. д. К протоколам прикладного уровня относят: DNS, FTP, BOOTP, BitTorrent, NFS, RTP, SMTP и т. д.
В случае с HTTPS его принадлежность к L7 или L6 определяется способом использования. Если пользователь занимается веб-серфингом, то протокол относят к прикладному уровню. Если же осуществляется передача финансовых данных, то низкоуровневый HTTPS рассматривают как L6.
Седьмой уровень отвечает за представление данных в понятном пользователю виде. На этом этапе не происходит доставка или маршрутизация информации. Протоколы просто преобразуют данные для визуализации. Кроме преобразования данных они также обеспечивают доступ к удаленным БД, пересылают служебную информацию.
## **ARP**
**ARP** - (Address Resolution Protocol — протокол определения адреса) (L3), определяет соответствие между логическим адресом сетевого уровня (IP) и физическим адресом устройства (MAC). Информация об известных IP и MAC-адресах хранится в виде таблицы (ARP-таблица) с данными, что позволяет устройствам не тратить время на повторную идентификацию.\
Перед тем, как передать пакет сетевого уровня через сегмент Ethernet, сетевой стек проверяет кэш ARP, чтобы выяснить, не зарегистрирована ли уже в его таблице нужная информация об узле-получателе. Если такой записи в кэше ARP нет, ARP-запрос отправляется на широковещательный MAC-адрес ff:ff:ff:ff:ff:ff. В теле ARP-запроса поле с неизвестным значением Target MAC Address заполняется нулями. ARP-ответ отправляется на MAC-адрес получателя, отправившего ARP-запрос. В поле Sender MAC Address указывается запрашиваемый MAC-адрес устройства. Поле opcode в заголовке ARP может принимает значение 1 для ARP-запроса и значение 2 для ARP-ответа.

**Gratuitous ARP** - используется для оповещения устройств в рамках широковещательного домена о появлении новой привязки IP-адреса и MAC-адреса. Когда сетевой интерфейс устройства получает настройки IP (вручную или по DHCP), устройство отправляет Gratuitous ARP сообщение, чтобы уведомить соседей о своём присутствии. Gratuitous ARP сообщение представляет собой особый вид ARP-ответа. Поле opcode принимает значение 2 (ARP-ответ). MAC-адрес получается как в заголовке Ethernet, так и в теле ARP-ответа является широковещательным (ff:ff:ff:ff:ff:ff). Поле Target IP Address в теле ARP-ответа совпадает с полем Sender IP Address.
C помощью GARP можно уведомить о смене MAC-адреса или обнаружить конфликты IP-адресов. Другой пример — использование протоколов резервирования первого перехода (First Hop Redundancy Protocols), например, HSRP у Cisco. Напомню, HSRP позволяет иметь виртуальный IP-адрес, разделённый между двумя или более сетевыми устройствами. В нормальном режиме работы обслуживание виртуального IP-адреса (ответы на ARP-запросы и т.д.) обеспечивает основное устройство. При отказе основного устройства обслуживание виртуального IP-адреса переходит ко второму устройству. Чтобы уведомить о смене MAC-адреса ответственного устройства, как раз отправляется GARP-сообщения.

## **ETHERNET**
**Ethernet** — семейство технологий пакетной передачи данных между устройствами для компьютерных и промышленных сетей.
Стандарты Ethernet определяют проводные соединения и электрические сигналы на физическом уровне, формат кадров и протоколы управления доступом к среде — на канальном уровне модели OSI. Ethernet в основном описывается стандартами IEEE группы 802.3. Ethernet стал одной из самых распространённых технологий ЛВС в середине 1990-х годов, вытеснив такие устаревшие технологии, как Token Ring, FDDI и ARCNET.\
Название «Ethernet» (буквально «эфирная сеть» или «среда сети») отражает первоначальный принцип работы этой технологии: всё, передаваемое одним узлом, одновременно принимается всеми остальными (то есть имеется некое сходство с радиовещанием). В настоящее время практически всегда подключение происходит через коммутаторы (switch), так что кадры, отправляемые одним узлом, доходят лишь до адресата (исключение составляют передачи на широковещательный адрес) — это повышает скорость работы и безопасность сети.\
Заголовок Ethernet-кадра содержит аппаратные адреса (MAC-адреса (Media Access Control)) отправителя и получателя, что позволяет определить, какое устройство отправило кадр и какое устройство должно получить и обработать его.
(Заголовок vlan (802.1Q) содержит TPID (16 бит) и TSI (16 бит) который состоит из PCP (3 бита), CFI (1 бит) и VID (12 бит)-4096 vlan)

  Формат Ethernet кадра, Ethernet+Vlan
  ![Формат кадра](https://user-images.githubusercontent.com/20071841/196447607-b5703e27-3b33-437f-b065-17aca42ec68e.png)

**MAC-адреса**\
При проектировании стандарта Ethernet было предусмотрено, что каждая сетевая карта (равно как и встроенный сетевой интерфейс) должна иметь уникальный шестибайтный номер (MAC-адрес), прошитый в ней при изготовлении. Этот номер используется для идентификации отправителя и получателя кадра, и предполагается, что при появлении в сети нового компьютера (или другого устройства, способного работать в сети) сетевому администратору не придётся настраивать MAC-адрес.\
Уникальность MAC-адресов достигается тем, что каждый производитель получает в координирующем комитете IEEE Registration Authority диапазон из шестнадцати миллионов (224) адресов, и по мере исчерпания выделенных адресов может запросить новый диапазон. Поэтому по трём старшим байтам MAC-адреса можно определить производителя. Существуют таблицы, позволяющие определить производителя по MAC-адресу; в частности, они включены в программы типа arpalert.

## **IPv4**
IPv4 (англ. Internet Protocol version 4) — четвёртая версия интернет-протокола (IP). Первая широко используемая версия. Протокол описан в RFC 791 (сентябрь 1981 года), заменившем RFC 760 (январь 1980 года).
Представление адреса
IPv4 использует 32-битные (четырёхбайтные) адреса, ограничивающие адресное пространство 4 294 967 296 (232) возможными уникальными адресами.
Традиционной формой записи IPv4-адреса является запись в виде четырёх десятичных чисел (от 0 до 255), разделённых точками. Через дробь указывается длина маски подсети.

**Классовая адресация**\
Классовая адресация сетей — метод IP-адресации. Применение этого метода не позволяет экономно использовать ограниченный ресурс IP-адресов, поскольку невозможно применение различных масок подсетей к различным подсетям. Адресное пространство было разделено на несколько логических групп и в каждой группе отводилось разное соотношение хостов и подсетей. Эти группы носят названия классов сетей и пронумерованы латинскими буквами: A, B, C, D и E. Деление основывается на старших битах адреса.

>Структура IP адреса согласно классовой модели

| СЕТЬ | ХОСТ |
| --------- | -------- |


| Класс | Первый биты | Начальный адрес | Конечный адрес |
| --- | --- | --- | --- |
| A | 0 | 0.0.0.0 | 127.255.255.255 |
| B | 10 | 128.0.0.0 | 191.255.255.255 |
| C | 110 | 192.0.0.0 | 223.255.255.255 |
| D | 1110 | 224.0.0.0 | 239.255.255.255 |
| E | 1111 | 240.0.0.0 | 255.255.255.255 |

>Класс А: 0.0.0.0 — 127.255.255.255\
Первый бит адреса равен нулю. Адрес сети занимает 7 бит, адрес узла — 24 бита, следовательно класс A содержит 128 подсетей по 16 777 216 адресов в каждой.\
![image](https://user-images.githubusercontent.com/20071841/198233386-42f68dce-bdc7-42af-9aa5-f7fb67787122.png)

>Класс B: 128.0.0.0 — 191.255.255.255\
Адрес начинается с битов 10. Адрес сети занимает 14 бит, адрес узла — 16, следовательно класс B содержит 16 384 подсетей по 65 536 адресов в каждой.\
![image](https://user-images.githubusercontent.com/20071841/198232955-ad235b01-5acf-443b-af88-28e02e597871.png)


>Класс C: 192.0.0.0 — 223.255.255.255\
Адрес начинается с битов 110. Адрес сети занимает 21 бит, адрес узла — 8 бит, следовательно класс C содержит 2 097 152 сетей по 256 адресов в каждой.\
![image](https://user-images.githubusercontent.com/20071841/198234446-0fae5c58-f35f-4a9e-ae9e-77acbde52b09.png)

>Класс D: 224.0.0.0 — 239.255.255.255\
Адрес начинается с битов 1110.Используется для многоадресной рассылки.\
![image](https://user-images.githubusercontent.com/20071841/198234959-5b70a016-5f1e-4ecd-a20b-50b0ef89f205.png)

>Класс Е: 240.0.0.0 — 255.255.255.255\
Адрес начинается с битов 1111. Такие адреса запрещены. Зарезервировано для использования в будущем.\
![image](https://user-images.githubusercontent.com/20071841/198235112-92d45c0d-1c03-4621-808a-7ba38e18b884.png)


**Бесклассовая адресация**
С ростом сети Интернет эта система оказалась неэффективной и была дополнена бесклассовой адресацией (CIDR). Была введена дополнительная метрика — маска подсети, определяющая, сколько бит адреса отводится на адрес сети, а сколько — на адрес узла.

>Структура IP адреса согласно бесклассовой модели CIDR

| СЕТЬ | ПОДСЕТЬ | ХОСТ |
| --- | --- | --- |

Диапазоны адресов
IP-адрес является массивом бит. Принцип IP-адресации — выделение множества (диапазона, блока, подсети) IP-адресов, в котором некоторые битовые разряды имеют фиксированные значения, а остальные разряды пробегают все возможные значения. Блок адресов задаётся указанием начального адреса и маски подсети. Бесклассовая адресация основывается на переменной длине маски подсети (англ. variable length subnet mask, VLSM), в то время, как в классовой (традиционной) адресации длина маски строго фиксирована 0, 1, 2 или 3 установленными октетами.

Бесклассовая адресация реализуется за счет сетевой маски, которая определяет какие биты будут относиться к номеру сети, а какие к хостовой части\
>В маске единицы блокируют биты, которые будут использованы для указания номера сети, нули же указывают на биты хостовой части. В двоичном виде маски, всегда в начале непрерывно идут единицы, а потом непрерывно нули.

| Класс | Маска класса | Двоичный вид |
| --- | --- | --- |
| A | 255.0.0.0 | 11111111.00000000.00000000.00000000 |
| B | 255.255.0.0 | 11111111.11111111.00000000.00000000 |
| C | 255.255.255.0 | 11111111.11111111.11111111.00000000 |

>Префикс (prefix) – количество единиц в маске (подразумевая маску в двоичном виде).

*Для маски 255.255.255.0 префикс будет выглядеть так – /24. Мы знаем, что 255 можно представить в двоичном виде как 8 единиц, в этой маске число 255 встречается 3 раза, следовательно единиц в маске 24. Вот так и получается префикс. Еще один простой пример для закрепления. Для маски 255.255.0.0 префикс будет выглядеть так – /16, т.к. число 255 встречается два раза. Префикс нужен для краткой записи маски например, строка 176.130.0.0 255.255.255.0 и строка 176.130.0.0/24, означает одно и тоже.*

Когда маска “не классовая” и начинает дробить октет, ее можно отнести к “сложной маске”. Представим все значения, которые могут быть в октете маски:

- 0 в двоичном виде 00000000
- 128 в двоичном виде 10000000
- 192 в двоичном виде 11000000
- 224 в двоичном виде 11100000
- 240 в двоичном виде 11110000
- 248 в двоичном виде 11111000
- 252 в двоичном виде 11111100
- 254 в двоичном виде 11111110
- 255 в двоичном виде 11111111

>Private IP (частные, личные)– адреса неиспользуемые в публичной сети Интернет, предназначены исключительно для использования в частных сетях.

| Класс |	Номер сети | Диапазон адресов|
| --- | --- | --- |
| A | 10.0.0.0/8 | 10.0.0.0 – 10.255.255.255 |
| B | 172.16.0.0/12 | 172.16.0.0 – 172.31.255.255 |
| C | 192.168.0.0/16	| 192.168.0.0 – 192.168.255.255 |

>Cписок всех возможных масок
>
| Маска |	Префикс | Маска |	Префикс | Маска |	Префикс |
| --- | --- | --- | --- | --- | --- |
| 255.255.255.255 | /32 | 255.255.248.0 | /21 | 255.192.0.0 | /10 |
| 255.255.255.254 | /31 | 255.255.240.0 | /20 | 255.128.0.0 | /9 |
| 255.255.255.252 | /30 | 255.255.224.0 | /19 | 255.0.0.0 | /8 |
| 255.255.255.248 | /29 | 255.255.192.0 | /18 | 254.0.0.0 | /7 |
| 255.255.255.240 | /28 | 255.255.128.0 | /17 | 252.0.0.0 | /6 |
| 255.255.255.224 | /27 | 255.255.0.0 | /16 | 248.0.0.0 | /5 |
| 255.255.255.192 | /26 | 255.254.0.0 | /15 | 240.0.0.0 | /4 |
| 255.255.255.128 | /25 | 255.252.0.0 | /14 | 224.0.0.0 | /3 |
| 255.255.255.0 | /24 | 255.248.0.0 | /13 | 192.0.0.0 | /2 |
| 255.255.254.0 | /23 | 255.240.0.0 | /12 | 128.0.0.0 | /1 |
| 255.255.252.0 | /22 | 255.224.0.0 | /11 | 0.0.0.0 | /0 |


## **ПОРТЫ TCP**
В современных компьютерных сетях из стека сетевых протоколов TCP/IP на транспортном уровне чаще всего используются TCP и UDP. Две конечные точки (хосты) при установке соединения по этим протоколам идентифицируются согласно номерам портов.
Количество портов ограничено с учётом 16-битной адресации (216=65536, начало — «0»). Все порты разделены на три диапазона — общеизвестные (или системные, 0—1023), зарегистрированные (или пользовательские, 1024—49151) и динамические (или частные, 49152—65535).

Пример: 20-21 - FTP; 22 - SSH; 23 - Telnet; 25 - SMTP (Simple Mail Transfer Protocol); 80 - HTTP (Hyper Text Transfer Protocol); 110 - POP3 (Post Office Protocol)


## **МАРШРУТИЗАЦИЯ**
>Конечные устройства, при передаче пакетов, полагаются на следующую логику:
Если IP адрес получателя находится в той же самой подсети (т.е. относится к тому же номеру сети и принадлежит тому же диапазону) что и IP адрес отправителя, то устройство отправляет пакет напрямую получателю.
Если IP адрес получателя находится в другой подсети (т.е. относится к другому номеру сети, а значит принадлежит другому диапазону), то устройство отправляет пакет на шлюз по умолчанию (default gateway). Чаще всего это интерфейс маршрутизатора (router).\

>Маршрутизатор (Router) – сетевое устройство, соединяющее части сети для передачи IP-пакетов. Основная функция роутеров – маршрутизация.

>Правила группировки адресов:
Все IP адреса в одной группе не должны быть разделены маршрутизатором (router).
Все IP адреса разделенные маршрутизатором должны быть в разных группах.

Из правил группировки адресов мы можем заключить, что на каждом интерфейсе у маршрутизатора должны быть разные IP адреса, принадлежащее разным номерам сетей.

Прежде чем разобрать большой пример, укажем несколько важных моментов:
- на протяжении всего пути IP пакет не меняется (!);
- при переходе пакета из одной подсети в другую, меняется фрейм, он является транспортом для переноса пакета внутри одного сегмента сети (!);
- номера сетей, подключенные к маршрутизатору напрямую, по умолчанию появляются в таблице маршрутизации (!);
- так же маршруты бывают либо статические,человек сам прописывает их, либо динамические, появившиеся при помощи протоколов маршрутизации (!).
#

## **СЕГМЕНТ СЕТИ**
>Сегме́нт сети — логически или физически обособленная часть сети.

Разбиение сети на сегменты осуществляется с целью оптимизации сетевого трафика и/или повышения безопасности сети в целом.

**Физическое разделение**\
Как правило, физический сегмент сети ограничен сетевым устройством, обеспечивающим соединение узлов сегмента с остальной сетью:
- Коммутаторы (2-й уровень в модели OSI)
- Маршрутизаторы (3-й уровень в модели OSI)

Физический сегмент сети является доменом коллизий. Устройства, работающие на первом уровне модели OSI (повторители или концентраторы), домен коллизий не ограничивают.

**Логическое разделение**\
Широко практикуемое разделение сети, основанной на протоколе IP (на логические сегменты или логические подсети). Для этого каждому сегменту выделяется диапазон адресов, который задается адресом сети и сетевой маской. Например (в CIDR записи):
- 192.168.1.0/24, 192.168.2.0/24, 192.168.3.0/24 и т. д. — в каждом сегменте до 254 узлов
- 192.168.0.0/25, 192.168.128.0/26, 192.168.172.0/27 — в сегментах до 126, 62, 30 узлов соответственно

Логические подсети соединяются с помощью маршрутизаторов.


## **ДОМЕН КОЛЛИЗИЙ/ШИРОКОВЕЩАТЕЛЬНЫЙ ДОМЕН**
Доме́н колли́зий (англ. Collision domain) — часть сети Ethernet, все узлы которой конкурируют за общую разделяемую среду передачи и, следовательно, каждый узел которой может создать коллизию с любым другим узлом этой части сети.

Другими словами — сегмент сети, имеющий общий канальный уровень модели OSI, в котором передать фрейм может только один абонент одновременно. Задержка распространения фреймов между станциями, либо одновременное начало передачи вызывает возникновение коллизий, которые требуют специальной обработки и снижают производительность сети.

Чем больше узлов в таком сегменте — тем выше вероятность коллизий. Для разделения домена коллизий применяются коммутаторы.

Понятие существует независимо от применяемого стандарта физического уровня.

Сетевые устройства и домен коллизий
Сетевые устройства, работающие на канальном уровне модели OSI, могут продлевать, либо ограничивать домен коллизий.

Возможны следующие варианты:

Устройства первого уровня OSI (концентраторы, повторители) только ретранслируют любой сигнал, поступающий из среды передачи, и продлевают домен коллизий.
Устройства второго уровня OSI (мосты, коммутаторы), разделяют домен коллизий.
Домен коллизий отдельный при подключении к порту коммутатора в полудуплексном режиме, либо при соединении типа «точка-точка» двух сетевых адаптеров; в полнодуплексном режиме коллизии отсутствуют.

**Домен коллизий**\
Когда устройство отправляет сообщение в сеть, все другие устройства, включенные в его домен коллизии, должны обращать на него внимание, независимо от того, предназначено оно им или нет. Это вызывает проблему, потому что в ситуации, когда два устройства отправляют свои сообщения одновременно, возникает конфликт, заставляющий их ждать и повторно передавать свои соответствующие сообщения по одному. Помните, это происходит только в случае полудуплексного режима.

**Широковещательный домен**\
Широковещательный домен - это совокупность всех портов коммутаторов соединенных в один сегмент.
Как мы уже говорили выше, к широковещанию прибегает сам коммутатор, когда получает кадр MAC-адрес которого отсутствует в MAC-таблице, а также узлы сети, отправляя кадры на адрес FF:FF:FF:FF:FF:FF, такие кадры будут доставлены всем узлам сети в широковещательном сегменте.
Исходя из этого, мы можем понять, что чем больше количество конфликтных доменов и чем больше количество широковещательных доменов, тем более эффективна сеть, обеспечивающая лучшую пропускную способность для всех своих пользователей.

- **Концентратор**\
Мы начинаем с хаба, потому что от него нужно избавиться как можно скорее. Причина в том, что он не нарушает ни домен коллизий, ни широковещательный домен, т.е. Концентратор не является ни разделителем доменов коллизий, ни разделителем широковещательных доменов. Все устройства, подключенные к концентратору, находятся в едином коллизионном и едином широковещательном домене. Помните, концентраторы не сегментируют сеть, они просто соединяют сегменты сети.

- **Коммутатор**\
Коммутатор позволяет разделять домен коллизий на отдельные домены по числу портов, таким образом каждый порт коммутатора - это отдельный домен коллизий и в каждом из них данные могут передаваться одновременно, не мешая друг другу. Они никогда не разбивают широковещательные домены, что означает, что это не разделитель широковещательных доменов. Все порты коммутатора по-прежнему находятся в одном широковещательном домене. Если устройство отправляет широковещательное сообщение, это все равно вызовет перегрузку.

- **Маршрутизатор**\
Маршрутизатор не только разрушает домены коллизий, но и разбивает широковещательные домены, что означает, что это одновременно и коллизия, и разделитель широковещательных доменов. Маршрутизатор создает соединение между двумя сетями. Широковещательное сообщение из одной сети никогда не достигнет другой, поскольку маршрутизатор никогда не пропустит его.

## **VLAN**

>VLAN (аббр. от англ. Virtual Local Area Network) — виртуальная локальная компьютерная сеть. VLAN - уменьшает количество паразитного трафика и увеличивает производительность, а также повышает безопасность, так как ограничивает передачу кадров только своим широковещательным доменом.

Данная технология описана стандартом 802.1Q и предусматривает добавление к заголовкам кадра дополнительного поля, которое содержит в том числе определенную метку (тег) с номером виртуальной сети - VLAN ID, всего можно создать 4094 сети, для большинства применений этого достаточно.\
(Заголовок vlan (802.1Q) содержит TPID (16 бит) и TSI (16 бит) который состоит из PCP (3 бита), CFI (1 бит) и VID (12 бит)-4096 vlan)

Формат Ethernet кадра, Ethernet+Vlan
![Формат кадра](https://user-images.githubusercontent.com/20071841/196447607-b5703e27-3b33-437f-b065-17aca42ec68e.png)

В устройствах Cisco, протокол VTP (англ. VLAN Trunking Protocol) предусматривает VLAN-домены для упрощения администрирования. VTP также выполняет «чистку» трафика, направляя VLAN трафик только на те коммутаторы, которые имеют целевые VLAN-порты (функция VTP pruning). Коммутаторы Cisco в основном используют протокол 802.1Q Trunk вместо устаревшего проприетарного ISL (англ. Inter-Switch Link) для обеспечения совместимости информации.

По умолчанию на каждом порту коммутатора имеется сеть VLAN1 или VLAN управления. Сеть управления не может быть удалена, однако могут быть созданы дополнительные сети VLAN и этим альтернативным VLAN могут быть дополнительно назначены порты.

Native VLAN — это параметр каждого порта, который определяет номер VLAN, который получают все непомеченные (untagged) пакеты.

В Cisco используется следующая терминология портов:

- **access port** — порт принадлежащий одному VLAN’у и передающий нетегированный трафик. По спецификации cisco, access порт может принадлежать только одному VLAN’у, по умолчанию это первый (нетегированный) VLAN. Любой кадр, который проходит через access порт, помечается номером, принадлежащим этому VLAN’у.
- **trunk port** — порт передающий тегированный трафик одного или нескольких VLAN’ов. Этот порт, наоборот, не изменяет тег, а лишь пропускает кадры с тегами, которые разрешены на этом порту.\
Для того чтобы передать через порт трафик нескольких VLAN, порт переводится в режим транка.

Режимы интерфейса (режим по умолчанию зависит от модели коммутатора):\
- **auto** — Порт находится в автоматическом режиме и будет переведён в состояние trunk, только если порт на другом конце находится в режиме on или desirable. То есть если порты на обоих концах находятся в режиме «auto», то trunk применяться не будет.
- **desirable** — Порт находится в режиме «готов перейти в состояние trunk»; периодически передает DTP-кадры порту на другом конце, запрашивая удаленный порт перейти в состояние trunk (состояние trunk будет установлено, если порт на другом конце находится в режиме on, desirable, или auto).
- **trunk** — Порт постоянно находится в состоянии trunk, даже если порт на другом конце не поддерживает этот режим.
- **nonegotiate** — Порт готов перейти в режим trunk, но при этом не передает DTP-кадры порту на другом конце. Этот режим используется для предотвращения конфликтов с другим «не-cisco» оборудованием. В этом случае коммутатор на другом конце должен быть вручную настроен на использование trunk’а.

По умолчанию в транке разрешены все VLAN. Для того чтобы через соответствующий VLAN в транке передавались данные, как минимум, необходимо чтобы VLAN был активным. Активным VLAN становится тогда, когда он создан на коммутаторе и в нём есть хотя бы один порт в состоянии up/up.

## **ПЕТЛЯ КОММУТАЦИИ**
Петля коммутации (Bridging loop, Switching loop) - состояние в сети, при котором происходит бесконечная пересылка фреймов между коммутаторами, подключенными в один и тот же сегмент сети.

## **STP**
Spanning Tree Protocol (STP) — канальный протокол. Основной задачей STP является устранение петель в топологии произвольной сети Ethernet, в которой есть один или более сетевых мостов, связанных избыточными соединениями. STP решает эту задачу, автоматически блокируя соединения, которые в данный момент для полной связности коммутаторов являются избыточными.

STP относится ко второму уровню модели OSI. STP использует алгоритм STA (Spanning Tree Algorithm), результатом работы которого является граф в виде дерева (связный и без простых циклов)\
Для обмена информацией между собой свичи используют специальные пакеты, так называемые BPDU (Bridge Protocol Data Units). BPDU бывают двух видов: конфигурационные (Configuration BPDU) и панические “ААА, топология поменялась!” TCN (Topology Change Notification BPDU). Первые регулярно рассылаются корневым свичом (и ретранслируются остальными) и используются для построения топологии, вторые, как понятно из названия, отсылаются в случае изменения топологии сети (проще говоря, подключении\отключении свича). Конфигурационные BPDU содержат несколько полей, остановимся на самых важных:
- идентификатор отправителя (Bridge ID)
- идентификатор корневого свича (Root Bridge ID)
- идентификатор порта, из которого отправлен данный пакет (Port ID)
- стоимость маршрута до корневого свича (Root Path Cost)

 Так как устройства не знают и не хотят знать своих соседей, никаких отношений (смежности/соседства) они друг с другом не устанавливают. Они шлют BPDU из всех работающих портов на мультикастовый ethernet-адрес 01-80-c2-00-00-00 (по умолчанию каждые 2 секунды), который прослушивают все свичи с включенным STP.\
Итак, как же формируется топология без петель?\
Сначала выбирается так называемый корневой мост/свич (root bridge). Это устройство, которое STP считает точкой отсчета, центром сети; все дерево STP сходится к нему. Выбор базируется на таком понятии, как идентификатор свича (Bridge ID). Bridge ID это число длиной 8 байт, которое состоит из Bridge Priority (приоритет, от 0 до 65535, по умолчанию 32768+номер vlan или инстанс MSTP, в зависимости от реализации протокола), и MAC-адреса устройства. В начале выборов каждый коммутатор считает себя корневым, о чем и заявляет всем остальным с помощью BPDU, в котором представляет свой идентификатор как ID корневого свича. При этом, если он получает BPDU с меньшим Bridge ID, он перестает хвастаться своим и покорно начинает анонсировать полученный Bridge ID в качестве корневого. В итоге, корневым оказывается тот свич, чей Bridge ID меньше всех.

**Роли портов**\
После того, как коммутаторы померились айдями и выбрали root bridge, каждый из остальных свичей должен найти один, и только один порт, который будет вести к корневому свичу. Такой порт называется корневым портом (Root port). Чтобы понять, какой порт лучше использовать, каждый некорневой свич определяет стоимость маршрута от каждого своего порта до корневого свича. Эта стоимость определяется суммой стоимостей всех линков, которые нужно пройти кадру, чтобы дойти до корневого свича. В свою очередь, стоимость линка определяется просто- по его скорости (чем выше скорость, тем меньше стоимость). Процесс определения стоимости маршрута связан с полем BPDU “Root Path Cost” и происходит так:\
- Корневой свич посылает BPDU с полем Root Path Cost, равным нулю\
- Ближайший свич смотрит на скорость своего порта, куда BPDU пришел, и добавляет стоимость согласно таблице

| Скорость порта	| Стоимость STP (802.1d) |
| --- | --- |
| 10 Mbps |	100 |
| 100 Mbps |	19 |
| 1 Gbps	| 4 |
| 10 Gbps	| 2 |

- Далее этот второй свич посылает этот BPDU нижестоящим коммутаторам, но уже с новым значением Root Path Cost, и далее по цепочке вниз

Если имеют место одинаковые стоимости — корневым выбирается меньший порт.\
Далее выбираются назначенные (Designated) порты. Из каждого конкретного сегмента сети должен существовать только один путь по направлению к корневому свичу, иначе это петля. В данном случае имеем в виду физический сегмент, в современных сетях без хабов это, грубо говоря, просто провод. Назначенным портом выбирается тот, который имеет лучшую стоимость в данном сегменте. У корневого свича все порты — назначенные.\
И вот уже после того, как выбраны корневые и назначенные порты, оставшиеся блокируются, таким образом разрывая петлю.

**Состояния портов**\
Итак, в обычном (802.1D) STP существует 5 различных состояний:

- **блокировка (blocking)**: блокированный порт не шлет ничего. Это состояние предназначено, как говорилось выше, для предотвращения петель в сети. Блокированный порт, тем не менее, слушает BPDU (чтобы быть в курсе событий, это позволяет ему, когда надо, разблокироваться и начать работать)
- **прослушивание (listening)**: порт слушает и начинает сам отправлять BPDU, кадры с данными не отправляет (15 сек).
- **обучение (learning)**: порт слушает и отправляет BPDU, а также вносит изменения в CAM- таблицу, но данные не перенаправляет (15 сек).
- **перенаправление\пересылка (forwarding)**: этот может все: и посылает\принимает BPDU, и с данными оперирует, и участвует в поддержании таблицы mac-адресов. То есть это обычное состояние рабочего порта.
- **отключен (disabled)**: состояние administratively down, отключен командой shutdown. Понятное дело, ничего делать не может вообще, пока вручную не включат.

Порядок перечисления состояний не случаен: при включении (а также при втыкании нового провода), все порты на устройстве с STP проходят вышеприведенные состояния именно в таком порядке (за исключением disabled-портов). Возникает закономерный вопрос: а зачем такие сложности? А просто STP осторожничает. Ведь на другом конце провода, который только что воткнули в порт, может быть свич, а это потенциальная петля. Вот поэтому порт сначала 15 секунд (по умолчанию) пребывает в состоянии прослушивания — он смотрит BPDU, попадающие в него, выясняет свое положение в сети — как бы чего ни вышло, потом переходит к обучению еще на 15 секунд — пытается выяснить, какие mac-адреса “в ходу” на линке, и потом, убедившись, что ничего он не поломает, начинает уже свою работу. Итого, мы имеем целых 30 секунд простоя, прежде чем подключенное устройство сможет обмениваться информацией со своими соседями. Современные компы грузятся быстрее, чем за 30 секунд. Вот комп загрузился, уже рвется в сеть, истерит на тему “DHCP-сервер, сволочь, ты будешь айпишник выдавать, или нет?”, и, не получив искомого, обижается и уходит в себя, извлекая из своих недр айпишник автонастройки. Естественно, после таких экзерсисов, в сети его слушать никто не будет, ибо “не местный” со своим 169.254.x.x. Понятно, что все это не дело, но как этого избежать?

**Portfast**\
Для таких случаев используется особый режим порта — portfast. При подключении устройства к такому порту, он, минуя промежуточные стадии, сразу переходит к forwarding-состоянию. Само собой, portfast следует включать только на интерфейсах, ведущих к конечным устройствам (рабочим станциям, серверам, телефонам и т.д.), но не к другим свичам.

Есть очень удобная команда режима конфигурации интерфейса для включения нужных фич на порту, в который будут включаться конечные устройства: switchport host. Эта команда разом включает PortFast, переводит порт в режим access (аналогично switchport mode access), и отключает протокол PAgP (об этом протоколе подробнее в разделе агрегация каналов).

**Виды STP**\
STP довольно старый протокол, он создавался для работы в одном LAN-сегменте. А что делать, если мы хотим внедрить его в нашей сети, которая имеет несколько VLANов?\
Стандарт 802.1Q, о котором мы упоминали в статье о коммутации, определяет, каким образом вланы передаются внутри транка. Кроме того, он определяет один процесс STP для всех вланов. BPDU по транкам передаются нетегированными (в native VLAN). Этот вариант STP известен как CST (Common Spanning Tree). Наличие только одного процесса для всех вланов очень облегчает работу по настройке и разгружает процессор свича, но, с другой стороны, CST имеет недостатки: избыточные линки между свичами блокируются во всех вланах, что не всегда приемлемо и не дает возможности использовать их для балансировки нагрузки.\
Cisco имеет свой взгляд на STP, и свою проприетарную реализацию протокола — PVST (Per-VLAN Spanning Tree) — которая предназначена для работы в сети с несколькими VLAN. В PVST для каждого влана существует свой процесс STP, что позволяет независимую и гибкую настройку под потребности каждого влана, но самое главное, позволяет использовать балансировку нагрузки за счет того, что конкретный физический линк может быть заблокирован в одном влане, но работать в другом. Минусом этой реализации является, конечно, проприетарность: для функционирования PVST требуется проприетарный же ISL транк между свичами.\
Также существует вторая версия этой реализации — PVST+, которая позволяет наладить связь между свичами с CST и PVST, и работает как с ISL- транком, так и с 802.1q. PVST+ это протокол по умолчанию на коммутаторах Cisco.

**RSTP**\
Все, о чем мы говорили ранее в этой статье, относится к первой реализация протокола STP, которая была разработана в 1985 году Радией Перлман (ее стихотворение использовано в качестве эпиграфа). В 1990 году эта реализации была включена в стандарт IEEE 802.1D. Тогда время текло медленнее, и перестройка топологии STP, занимающая 30-50 секунд (!!!), всех устраивала. Но времена меняются, и через десять лет, в 2001 году, IEEE представляет новый стандарт RSTP (он же 802.1w, он же Rapid Spanning Tree Protocol, он же Быстрый STP). Чтобы структурировать предыдущий материал и посмотреть различия между обычным STP (802.1d) и RSTP (802.1w), соберем таблицу с основными фактами:

| **STP (802.1d)** | **RSTP (802.1w)** |
| --- | --- |
| В уже сложившейся топологии только корневой свич шлет BPDU, остальные ретранслируют | Все свичи шлют BPDU в соответствии с hello-таймером (2 секунды по умолчанию) |
| **Состояния портов** | **Состояния портов** |
| — блокировка (blocking) — прослушивание (listening) — обучение (learning) — перенаправление\пересылка (forwarding) — отключен (disabled) | — отбрасывание (discarding), заменяет disabled, blocking и listening — learning — forwarding |
| **Роли портов** | **Роли портов** |
| — корневой (root), участвует в пересылке данных, ведет к корневому свичу — назначенный (designated), тоже работает, ведет от корневого свича — неназначенный (non-designated), не участвует в пересылке данных | — корневой (root), участвует в пересылке данных — назначенный (designated), тоже работает — дополнительный (alternate), не участвует в пересылке данных — резервный (backup), тоже не участвует |
| **Механизмы работы** | **Механизмы работы** |
| Использует таймеры: Hello (2 секунды) Max Age (20 секунд) Forward delay timer (15 секунд) |  Forward delay timer (15 секунд)	Использует процесс proposal and agreement (предложение и соглашение) |
| Свич, обнаруживший изменение топологии, извещает корневой свич, который, в свою очередь, требует от всех остальных очистить их записи о текущей топологии в течение forward delay timer | Обнаружение изменений в топологии влечет немедленную очистку записей |
| Если не-корневой свич не получает hello- пакеты от корневого в течение Max Age, он начинает новые выборы | Начинает действовать, если не получает BPDU в течение 3 hello-интервалов |
| Последовательное прохождение порта через состояния Blocking (20 сек) — Listening (15 сек) — Learning (15 сек) — Forwarding | Быстрый переход к Forwarding для p2p и Edge-портов |

Как мы видим, в RSTP остались такие роли портов, как корневой и назначенный, а роль заблокированного разделили на две новых роли: Alternate и Backup. Alternate — это резервный корневой порт, а backup — резервный назначенный порт. Как раз в этой концепции резервных портов и кроется одна из причин быстрого переключения в случае отказа. Это меняет поведение системы в целом: вместо реактивной (которая начинает искать решение проблемы только после того, как она случилась) система становится проактивной, заранее просчитывающей “пути отхода” еще до появления проблемы. Смысл простой: для того, чтобы в случае отказа основного переключится на резервный линк, RSTP не нужно заново просчитывать топологию, он просто переключится на запасной, заранее просчитанный.\
Ранее, для того, чтобы убедиться, что порт может участвовать в передаче данных, требовались таймеры, т.е. свич пассивно ждал в течение означенного времени, слушая BPDU. Ключевой фичей RSTP стало введение концепции типов портов, основанных на режиме работы линка- full duplex или half duplex (типы портов p2p или shared, соответственно), а также понятия пограничный порт (тип edge p2p), для конечных устройств. Пограничные порты назначаются, как и раньше, командой spanning-tree portfast, и с ними все понятно- при включении провода сразу переходим к forwarding-состоянию и работаем. Shared-порты работают по старой схеме с прохождением через состояния BLK — LIS — LRN — FWD. А вот на p2p-портах RSTP использует процесс предложения и соглашения (proposal and agreement). Не вдаваясь в подробности, его можно описать так: свич справедливо считает, что если линк работает в режиме полного дуплекса, и он не обозначен, как пограничный, значит, на нем только два устройства- он и другой свич. Вместо того, чтобы ждать входящих BPDU, он сам пытается связаться со свичом на том конце провода с помощью специальных proposal BPDU, в которых, конечно, есть информация о стоимости маршрута к корневому свичу. Второй свич сравнивает полученную информацию со своей текущей, и принимает решение, о чем извещает первый свич посредством agreement BPDU. Так как весь этот процесс теперь не привязан к таймерам, происходит он очень быстро- только подключили новый свич- и он практически сразу вписался в общую топологию и приступил к работе (можете сами оценить скорость переключения в сравнении с обычным STP на видео). В Cisco-мире RSTP называется PVRST (Per-Vlan Rapid Spanning Tree).

**MSTP**\
Чуть выше, мы упоминали о PVST, в котором для каждого влана существует свой процесс STP. Вланы это довольно удобный инструмент для многих целей, и поэтому, их может быть достаточно много даже в некрупной организации. И в случае PVST, для каждого будет рассчитываться своя топология, тратиться процессорное время и память свичей. А нужно ли нам рассчитывать STP для всех 500 вланов, когда единственное место, где он нам нужен- это резервный линк между двумя свичами? Тут нас выручает MSTP. В нем каждый влан не обязан иметь собственный процесс STP, их можно объединять. Вот у нас есть, например, 500 вланов, и мы хотим балансировать нагрузку так, чтобы половина из них работала по одному линку (второй при этом блокируется и стоит в резерве), а вторая- по другому. Это можно сделать с помощью обычного STP, назначив один корневой свич в диапазоне вланов 1-250, а другой- в диапазоне 250-500. Но процессы будут работать для каждого из пятисот вланов по отдельности (хотя действовать будут совершенно одинаково для каждой половины). Логично, что тут хватит и двух процессов. MSTP позволяет создавать столько процесов STP, сколько у нас логических топологий (в данном примере- 2), и распределять по ним вланы. Думаем, нет особого смысла углубляться в теорию и практику MSTP в рамках этой статьи (ибо теории там ого-го), интересующиеся могут пройти по ссылке.

**Агрегация каналов**\
Но какой бы вариант STP мы не использовали, у нас все равно существует так или иначе неработающий линк. А возможно ли задействовать параллельные линки по полной и при этом избежать петель? Это называется link aggregation, link bundling, NIC teaming, port trunkinkg\
Технологии агрегации (объединения) каналов выполняют 2 функции: с одной стороны, это объединение пропускной способности нескольких физических линков, а с другой — обеспечение отказоустойчивости соединения (в случае падения одного линка нагрузка переносится на оставшиеся). Объединение линков можно выполнить как вручную (статическое агрегирование), так и с помощью специальных протоколов: LACP (Link Aggregation Control Protocol) и PAgP (Port Aggregation Protocol).\
LACP, опеределяемый стандартом IEEE 802.3ad, является открытым стандартом, то есть от вендора оборудования не зависит. Соответственно, PAgP — проприетарная цисковская разработка.
>**EtherChannel**— технология агрегации каналов, разработанная компанией Cisco Systems. Технология позволяет объединять несколько физических каналов Ethernet в один логический для увеличения пропускной способности и повышения надёжности соединения. **Port-channel** - это имя виртуального интерфейса Cisco для объединения каналов.\
EtherChannel даёт возможность объединять от двух до восьми 100 Мбит/с, 1 Гбит/с или 10 Гбит/с портов Ethernet (все порты в канале должны иметь одинаковую скорость), работающего по витой паре или по оптоволокну, что позволяет достичь результирующей скорости до 80 Гбит/с. Дополнительно, от одного до семи портов могут быть неактивны и включаться в работу при обрыве соединения по одному из активных портов. При отсутствии резервных портов, трафик автоматически распределяется по всем активным соединениям.\
Канал может устанавливаться между маршрутизаторами, коммутаторами и сетевыми адаптерами на сервере. Все сетевые адаптеры, являющиеся частью канала, получают один MAC-адрес, что делает канал прозрачным для сетевых приложений. Балансировка трафика между портами производится на основе хеш-функции над MAC-адресом, IP-адресом или TCP и UDP портом источника или получателя. Таким образом, в некоторых неблагоприятных случаях, весь трафик может передаваться по одному физическому соединению.

При использовании протокола STP вместе с EtherChannel, все соединения в канале рассматриваются как одно логическое и BPDU посылается только по одному из них. Специальный алгоритм позволяет выявить несоответствия, когда один из коммутаторов не сконфигурирован для работы с каналом.

При настройке EtherChannel, порты на обеих сторонах канала добавляются к нему вручную, или используется один из протоколов автоматической агрегации портов: проприетарный протокол Cisco PAgP, или описанный в стандарте IEEE 802.3ad LACP.

**Port security**\
Теперь расскажем вкратце, как обеспечить безопасность сети на втором уровне OSI. В этой части статьи теория и практическая конфигурация совмещены. Увы, Packet Tracer не умеет ничего из упомянутых в этом разделе команд, поэтому все без иллюстраций и проверок.\
Для начала, следует упомянуть команду конфигурации интерфейса switchport port-security, включающую защиту на определенном порту свича. Затем, с помощью switchport port-security maximum 1 мы можем ограничить количество mac-адресов, связанных с данным портом (т.е., в нашем примере, на данном порту может работать только один mac-адрес). Теперь указываем, какой именно адрес разрешен: его можно задать вручную switchport port-security mac-address адрес, или использовать волшебную команду switchport port-security mac-address sticky, закрепляющую за портом тот адрес, который в данный момент работает на порту. Далее, задаем поведение в случае нарушения правила switchport port-security violation {shutdown | restrict | protect}: порт либо отключается, и потом его нужно поднимать вручную (shutdown), либо отбрасывает пакеты с незарегистрированного мака и пишет об этом в консоль (restrict), либо просто отбрасывает пакеты (protect).\
Помимо очевидной цели — ограничение числа устройств за портом — у этой команды есть другая, возможно, более важная: предотвращать атаки. Одна из возможных — истощение CAM-таблицы. С компьютера злодея рассылается огромное число кадров, возможно, широковещательных, с различными значениями в поле MAC-адрес отправителя. Первый же коммутатор на пути начинает их запоминать. Одну тысячу он запомнит, две, но память-то оперативная не резиновая, и среднее ограничение в 16000 записей будет довольно быстро достигнуто. При этом дальнейшее поведение коммутатора может быть различным. И самое опасное из них с точки зрения безопасности: коммутатор может начать все кадры, приходящие на него, рассылать, как широковещательные, потому что MAC-адрес получателя не известен (или уже забыт), а запомнить его уже просто некуда. В этом случае сетевая карта злодея будет получать все кадры, летающие в вашей сети.

**DHCP Snooping**
Другая возможная атака нацелена на DHCP сервер. Как мы знаем, DHCP обеспечивает клиентские устройства всей нужной информацией для работы в сети: ip-адресом, маской подсети, адресом шюза по умолчанию, DNS-сервера и прочим. Атакующий может поднять собственный DHCP, который в ответ на запрос клиентского устройства будет отдавать в качестве шлюза по умолчанию (а также, например, DNS-сервера) адрес подконтрольной атакующему машины. Соответственно, весь трафик, направленный за пределы подсети обманутыми устройствами, будет доступен для изучения атакующему — типичная man-in-the-middle атака. Либо такой вариант: подлый мошенник генерируют кучу DHCP-запросов с поддельными MAC-адресами и DHCP-сервер на каждый такой запрос выдаёт IP-адрес до тех пор, пока не истощится пул.\
Для того, чтобы защититься от подобного вида атак, используется фича под названием DHCP snooping. Идея совсем простая: указать свичу, на каком порту подключен настоящий DHCP-сервер, и разрешить DHCP-ответы только с этого порта, запретив для остальных. Включаем глобально командой ip dhcp snooping, потом говорим, в каких вланах должно работать ip dhcp snooping vlan номер(а). Затем на конкретном порту говорим, что он может пренаправлять DHCP-ответы (такой порт называется доверенным): ip dhcp snooping trust.

**IP Source Guard**
После включения DHCP Snooping’а, он начинает вести у себя базу соответствия MAC и IP-адресов устройств, которую обновляет и пополняет за счет прослушивания DHCP запросов и ответов. Эта база позволяет нам противостоять еще одному виду атак — подмене IP-адреса (IP Spoofing). При включенном IP Source Guard, каждый приходящий пакет может проверяться на:
- соответствие IP-адреса источника адресу, полученному из базы DHCP Snooping (иными словами, айпишник закрепляется за портом свича)
- соответствие MAC-адреса источника адресу, полученному из базы DHCP Snooping

Включается IP Source Guard командой ip verify source на нужном интерфейсе. В таком виде проверяется только привязка IP-адреса, чтобы добавить проверку MAC, используем ip verify source port-security. Само собой, для работы IP Source Guard требуется включенный DHCP snooping, а для контроля MAC-адресов должен быть включен port security.

**Dynamic ARP Inspection**\
Как мы уже знаем, для того, чтобы узнать MAC-адрес устройства по его IP-адресу, используется проткол ARP: посылается широковещательный запрос вида “у кого ip-адрес 172.16.1.15, ответьте 172.16.1.1”, устройство с айпишником 172.16.1.15 отвечает. Подобная схема уязвима для атаки, называемой ARP-poisoning aka ARP-spoofing: вместо настоящего хоста с адресом 172.16.1.15 отвечает хост злоумышленника, заставляя таким образом трафик, предназначенный для 172.16.1.15 следовать через него. Для предотвращения такого типа атак используется фича под названием Dynamic ARP Inspection. Схема работы похожа на схему DHCP-Snooping’а: порты делятся на доверенные и недоверенные, на недоверенных каждый ARP-ответ подвергаются анализу: сверяется информация, содержащаяся в этом пакете, с той, которой свич доверяет (либо статически заданные соответствия MAC-IP, либо информация из базы DHCP Snooping). Если не сходится- пакет отбрасывается и генерируется сообщение в syslog. Включаем в нужном влане (вланах): ip arp inspection vlan номер(а). По умолчанию все порты недоверенные, для доверенных портов используем ip arp inspection trust.

## **VRRP**
VRRP(Virtual Router Redundancy Protocol) — сетевой протокол, предназначенный для увеличения доступности маршрутизаторов, выполняющих роль шлюза по умолчанию. Это достигается путём объединения группы маршрутизаторов в один виртуальный маршрутизатор и назначения им общего IP-адреса, который и будет использоваться как шлюз по умолчанию для компьютеров в сети.

**Терминология протокола**
- VRRP-маршрутизатор (VRRP Router) — физический маршрутизатор, на котором работает протокол VRRP. Он может участвовать в одном или более виртуальных маршрутизаторах.
- Виртуальный маршрутизатор (Virtual Router, VR) — абстрактный объект, которым управляет VRRP. Выполняет роль "маршрутизатора по умолчанию" для компьютеров в сети. Фактически, виртуальный маршрутизатор — это группа интерфейсов маршрутизаторов, которые находятся в одной сети и разделяют Virtual Router Identifier (VRID) и виртуальный IP-адрес.
- Владелец IP-адреса (IP Address Owner) — VRRP-маршрутизатор, который использует IP-адрес, назначенный виртуальному маршрутизатору, как реальный IP-адрес присвоенный интерфейсу.
- VRRP-объявление (ADVERTISEMENT) — сообщения, которые отправляет Master-маршрутизатор.
- Виртуальный IP-адрес (Virtual IP address) — это IP-адрес, присвоенный интерфейсу одного из маршрутизаторов, которые составляют Virtual Router. Используется также название — основной IP-адрес (Primary IP Address). В VRRP-объявлениях в качестве адреса отправителя всегда используется виртуальный IP-адрес.
- Virtual Router Master или VRRP Master router — VRRP-маршрутизатор, который отвечает за отправку пакетов, отправленных на IP-адрес, который ассоциирован с виртуальным маршрутизатором, и за ответы на ARP-запросы, отправленные на этот адрес. Если владелец IP-адреса доступен, то он всегда становится Master.
- Virtual Router Backup или VRRP Backup router — это группа маршрутизаторов, которые находятся в режиме ожидания и готовы взять на себя роль VRRP Master router, как только текущий VRRP Master router станет недоступным.
- Виртуальный MAC-адрес (Virtual MAC) — 0000.5E00.01xx, где xx — номер группы VRRP.

**Описание протокола**\
Протокол VRRP предназначен для увеличения доступности маршрутизаторов выполняющих роль шлюза по умолчанию.\
Для группы маршрутизаторов настраивается их принадлежность виртуальному маршрутизатору. Фактически, виртуальный маршрутизатор — это группа интерфейсов маршрутизаторов, которые находятся в одной сети и разделяют Virtual Router Identifier (VRID) и виртуальный IP-адрес.\
VRRP-маршрутизатор может находиться в нескольких виртуальных маршрутизаторах, каждый с уникальной комбинацией VRID/IP-адрес. Соответствия между VRID и виртуальным IP-адресом должны быть одинаковыми на всех маршрутизаторах в одной сети.\
В любой момент времени только один из физических маршрутизаторов выполняет маршрутизацию трафика, то есть становится VRRP Master router, остальные маршрутизаторы в группе становятся VRRP Backup router. Если текущий VRRP Master router становится недоступным, то его роль берет на себя один из VRRP Backup маршрутизаторов, тот у которого наивысший приоритет. Задание приоритета позволяет определить более приоритетные пути административно.\
Backup-маршрутизатор не будет пытаться перехватить на себя роль Master-маршрутизатора, если только у него не более высокий приоритет, чем у текущего Master-маршрутизатора. VRRP позволяет административно запретить перехват роли Master-маршрутизатора. Единственное исключение из этого правила — VRRP-маршрутизатор всегда будет становиться Master, если он владелец IP-адреса, который присвоен виртуальному маршрутизатору.\
В каждом виртуальном маршрутизаторе только Master отправляет периодические VRRP-объявления на зарезервированный групповой адрес 224.0.0.18. На канальном уровне в качестве MAC-адреса отправителя VRRP-объявлений используется виртуальный MAC-адрес.


#

>Степени двойки

| 2^n |	= | 2^n | = | 2^n | = |
| --- | ---: | --- | ---: | --- | ---: |
| 0 | `1` | 11 | `2048` | 22 | `4 194 304` |
| 1 | `2` | 12 | `4096` | 23 | `8 388 608` |
| 2 | `4` | 13 | `8192` | 24 | `16 777 216` |
| 3 | `8` | 14 | `16384` | 25 | `33 554 432` |
| 4 | `16` | 15 | `32768` | 26 | `67 108 864` |
| 5 | `32` | 16 | `65 536` | 27 | `134 217 728` |
| 6 | `64` | 17 | `131 072` | 28 | `268 435 456` |
| 7 | `128` | 18 | `262 144` | 29 | `536 870 912` |
| 8 | `256` | 19 | `524 288` | 30 | `1 073 741 824` |
| 9 | `512` | 20 | `1 048 576` | 31 | `2 147 483 648` |
| 10 | `1024` | 21 | `2 097 152` |  32 | `4 294 967 296` |

 


# **Компетенция 1.2. Общие знания по серверному оборудованию. Высокий уровень**

*Администратор знает и понимает: состав компонентов, используемых в серверном оборудовании; принципы обеспечения отказоустойчивой и надежной работы серверного оборудования; принципы управления и мониторинга серверного оборудования; общие принципы настройки/обновления BIOS/UEFI серверного оборудования и назначение основных параметров BIOS/UEFI, существенно влияющих на работу компонентов виртуализации; принципы настройки/обновления микропрограммного обеспечения серверного оборудования; основные характеристики и понятия, используемые при построении RAID различных уровней; принципы настройки и основные параметры встроенных модулей управления; процесс организации технической поддержки серверного оборудования производителем  или подрядной организацией (в рамках контракта на техническую поддержку); процесс проверки совместимости серверных компонентов и установленного микропрограммного обеспечения и устанавливаемых ОС*
#
<details><summary>ВОПРОСЫ ПО ТЕМЕ</summary>
<p>
 
 - Можно ли использовать в RAID массиве диски разного размера?
 > Да, можно. Но, при этом, используемая емкость у ВСЕХ дисков будет равна емкости наименьшего диска.
 - Можно ли добавить в RAID массив диск большего размера?
> Добавлять в уже существующий RAID массив можно только диски такого же или большего размера.
 - Что такое Hotswap?
>Hot Swap - Горячая замена - это термин, обозначающий замену элемента, который дал сбой, не отключая питание.
(Замена блока питания, жесткого диска, вентилятора и прочего оборудования)
Обычно в серверах IBM, Lenovo оранжевая цветовая марикровка таких элементов.
 - Что такое Hot Spare (Hotspare)?
>Hot Spare - (Горячее резервирование) - в случае выхода из строя диска, восстанавливающая операция будет выполнена RAID контроллером автоматически, если назначен диск Hotspare в качестве резервного.
</p>
</details>

#

[Чем отличается BIOS от UEFI](https://habr.com/ru/post/404511/)

## **Особенности BIOS и UEFI, различие GPT и MBR**
>**UEFI** («Unified Extensible Firmware Interface»,  «интерфейс расширяемой прошивки»)\
**BIOS** («Basic Input/Output System», «базовая система ввода/вывода»)

Основные преимущества нового интерфейса UEFI:
 - Понятная и удобная графическая оболочка с поддержкой манипулятора.
 - Поддержка винчестеров с таблицей разделов GPT и адресацией LBA.
 - Полноценная работа с жесткими дисками, объем которых превышает 2 Тбайта.
 - Увеличенная скорость загрузки системы.
 - Наличие менеджера загрузки, который предоставляет выбор операционной системы.
 - Простота обновления прошивки.
 - Наличие технологии Secure Boot, которая обеспечивает защиту от установки ОС незащищенных ключами.

## **Типы RAID массивов**
>**RAID** (redundant array of independent disks — избыточный массив независимых дисков) – технологии виртуального хранения данных, объединяющей несколько физических дисков в один логический элемент.

**Аппаратные и программные RAID-массивы**
- Программные массивы создаются уже после установки Операционной Системы средствами программных продуктов и утилит, что и является главным недостатком таких дисковых массивов.
- Аппаратные RAID’ы создают дисковый массив до установки Операционной системы и от неё не зависят.

**RAID 0**\
RAID 0 (также называют «Striping» — Чередование) предполагает разделение информации на блоки и одновременная запись разных блоков на разные диски.\
Такая технология повышает скорость чтения/записи, позволяет пользователю использовать полный суммарный объем дисков, однако понижает отказоустойчивость, вернее сводит её на ноль. Так, в случае выхода из строя одного из дисков, восстановить информацию будет практически невозможно. Для сборки RAID 0 рекомендуется использовать исключительно высоконадежные диски.\
>Минимальное количество дисков: 2.

![image](https://user-images.githubusercontent.com/20071841/200758479-35cf7528-cd21-4dfa-abe8-462d7989491d.png)

**RAID 1**\
RAID 1 (mirroring — «зеркалирование») — массив из двух (или более) дисков, являющихся полными копиями друг друга. Не следует путать с массивами RAID 1+0 (RAID 10), RAID 0+1 (RAID 01), в которых используются более сложные механизмы зеркалирования.
- Обеспечивает приемлемую скорость записи (такую же, как и без дублирования) и выигрыш по скорости чтения при распараллеливании запросов.
- Имеет высокую надёжность — работает до тех пор, пока функционирует хотя бы один диск в массиве. Вероятность выхода из строя сразу двух дисков равна произведению вероятностей отказа каждого диска, то есть значительно ниже вероятности выхода из строя отдельного диска. На практике при выходе из строя одного из дисков следует срочно принимать меры — вновь восстанавливать избыточность. Для этого с любым уровнем RAID (кроме нулевого) рекомендуют использовать диски горячего резерва.
- Недостаток RAID 1 в том, что по цене двух (и более) жестких дисков пользователь фактически получает объём лишь одного.\
>Минимальное количество дисков: 2.

![image](https://user-images.githubusercontent.com/20071841/200761979-71852f71-f60e-4501-a5fe-75a72960f1d5.png)

**RAID 5**\
RAID 5 обеспечивает сравнимую с режимом RAID 0 производительность и при этом обеспечивает защиту данных. На все, кроме одного записывается рейд 0, а на последний специальная контрольная сумма, что позволяет сохранить информацию на винчестерах в случае «смерти» одного из них (но не более одного). Скорость работы такого массива высокая. На восстановление информации в случае замены диска потребуется много времени.\
>Минимальное количество дисков: 3.

![image](https://user-images.githubusercontent.com/20071841/200771474-68a949cc-da72-484f-be5e-fcae90beff9a.png)

**RAID 6**\
В режиме RAID 6 данные записываются на все диски в томе и в два блока четности для каждого блока данных. Если один физический диск выходит из строя, данные из неисправного диска можно восстановить на запасной диск. Используя два блока четности для каждого блока данных, режим RAID 6 поддерживает выход из строя до двух дисков без потери данных. Синхронизация в режиме RAID 6 из неисправного диска происходит медленнее, чем в режиме RAID 5, из-за двойной проверки четности. Однако это не так уж и важно благодаря двухдисковому уровню защиты. Режим RAID 6 обеспечивает очень хорошую защиту и немного низшую производительность по сравнению с режимом RAID 5.\
>Минимальное количество дисков: 4.

![image](https://user-images.githubusercontent.com/20071841/200775400-cb6f03a9-d879-4dce-a023-f8ace77a1e0e.png)

**RAID 10 (1+0)**\
В режиме RAID 10 сочетаются защита режима RAID 1 и производительность режима RAID 0. При использовании четырех дисков в режиме RAID 10 создается два сегмента RAID 1, которые объединяются в страйп RAID 0. При использовании восьми дисков в страйпе RAID 0 будет уже четыре сегмента RAID 1. Такие конфигурации обеспечивают исключительную защиту данных, при которой из строя могут выйти даже два диска в двух сегментах RAID 1. Кроме того, в режиме RAID 10 данные записываются на уровне файлов, а благодаря страйпу RAID 0 обеспечивается высшая производительность при работе с большим количеством файлов маленьких размеров. Это означает, что повышается уровень операций ввода-вывода в секунду. RAID 10 отличный выбор для администраторов баз данных, для которых требуется считывание и запись множества маленьких файлов на дисках тома. Впечатляющие уровни операций ввода-вывода в секунду и защиты данных, предоставляемые режимом RAID 10, обеспечивают для администраторов баз данных как надежность в сохранности файлов, так и быстрый доступ к ним.\
>Минимальное количество дисков: 4.

![image](https://user-images.githubusercontent.com/20071841/200775775-87baf4ab-d624-4fe8-b6b0-184bf91cc196.png)
#


#


## **IOPS** 
**IOPS** (количество операций ввода/вывода – от англ. Input/Output Operations Per Second) – один из ключевых параметров при измерении производительности систем хранения данных, жестких дисков (НЖМД), твердотельных диски (SSD) и сетевых хранилища данных (SAN).

Приложения которые интенсивно используют операции на запись являются хорошими кандидатами для RAID 10, тогда как приложения которые интенсивно используют операции на чтение могут быть размещены на RAID 5.

IOPS используются для определения производительности диска или дискового массива.\
Приблизительные значения IOPS для жестких дисков.:

| Интерфейс | Тип | IOPS |
| --- | :---: | ---: |
| SATA 3 Гбит/с |	HDD | ~75-150 |
| SAS |	HDD | ~150-210 |
| SATA 3 Гбит/с |	SSD | ~8 600 |
| SATA 6 Гбит/с |	SSD | ~60 000 |
| PCIe |	SSD | > ~200 000 |

>Для расчета фактического IOPS для диска требуется следующая информация: Average latency, Average seek time. Эту информацию можно получить от производителя

**Вычислим максимальный IOPS для диска**\
Для примера возьмем диск: Seagate ST500DM002-1BC142
```
Average latency (avgLatency): 4.16ms или 0.00416s
Average seek time (avgSeek): 8.5ms или 0.0085s
```
Чтобы вычислить IOPS используем уравнение:
```
IOPS = 1/(avgLatency + avgSeek)
IOPS = 1/(0.00416 + 0.0085) = 78,9889415
```
Итого, максимальный IOPS - 79.

**Максимальное значение IOPS для дискового массива**\
В примечании к разработке системы хранения, вычисление производительности дисковой системы имеет решающее значение для работы данной системы. Большинство систем используют RAID для обеспечения избыточности хранилища. В этом разделе описывается, как вычисляются IOPS для RAID-массивов.

**- Максимальное значение IOPS для чтения**\
Вычисление максимального значения IOPS чтения (maxReadIops) для RAID-массива:
```
maxReadIops = numDisks * diskMaxIops
```
Соответственно для массива из 4 дисков максимальное значение IOPS чтения будет следующим:
```
maxReadIops = 4 * 79
maxReadIops = 316
```
**- Максимальное значение IOPS для записи**\
Вычисление максимального значения IOPS записи (maxWriteIops) - это совсем другое в отношении RAID-массивов. RAID-массивы имеют штраф на запись, а тип RAID-массива определяет серьёзность штрафа. Этот штраф является результатом избыточности, которую предоставляет RAID, поскольку массив обязательно должен записывать данные на несколько дисков/локаций для обеспечения целостности данных.

!Штраф на запись RAID-массива\
Наиболее распространенные типы RAID и их штрафы на запись определяются в следующей таблице:

| RAID Type | Write Penalty |
| --- | :---: |
| RAID 0 |	1 |
| RAID 1 |	2 |
| RAID 5 |	4 |
| RAID 6 |	6 |
| RAID 10 |	2 |

Чтобы вычислить максимальное значение IOPS записи (maxWriteIops) для заданного RAID-массива, разделим максимальное значение IOPS чтения (maxReadIops) на штраф за запись RAID-массива (raidWritePenalty): 
```
maxWriteIops = maxReadIops / raidWritePenalty
```
Используя наш пример с 4-мя дисками и конфигурацией RAID 10, получаем следующие значения:
```
maxWriteIops = 316 / 2
maxWriteIops = 158
```
Итого, для нашего примера, максимальное значение IOPS на запись для массива RAID 10 - 158.

[IOPS](https://habr.com/ru/post/164325/)

## **S.M.A.R.T.**
S.M.A.R.T. - (от англ. self-monitoring, analysis and reporting technology — технология самоконтроля, анализа и отчётности) — технология оценки состояния жёсткого диска встроенной аппаратурой самодиагностики, а также механизм предсказания времени выхода его из строя.
>Накопители не могут самостоятельно сообщать о своём состоянии посредством технологии SMART, однако для этого существуют специальные программы. Таким образом, использование технологии S.M.A.R.T. невозможно без наличия следующих двух составляющих:
>- ПО, встроенного в контроллер накопителя;
>- Внешнего ПО, встроенного в хост.

## **SNMP**
SNMP - (англ. Simple Network Management Protocol — простой протокол сетевого управления) — стандартный интернет-протокол для управления устройствами в IP-сетях на основе архитектур TCP/UDP. К поддерживающим SNMP устройствам относятся маршрутизаторы, коммутаторы, серверы, рабочие станции, принтеры, модемные стойки и другие. Протокол обычно используется в системах сетевого управления для контроля подключённых к сети устройств на предмет условий, которые требуют внимания администратора. SNMP определён Инженерным советом интернета (IETF) как компонент TCP/IP. Он состоит из набора стандартов для сетевого управления, включая протокол прикладного уровня, схему баз данных и набор объектов данных.

**Сетевые порты SNMP**\
По умолчанию SNMP использует UDP-порты 161 и 162. Менеджер отправляет запросы на порт 161 агента. С порта 161 агент отправляет ответ менеджеру. При отправке запроса менеджер добавляет к нему ID, а агент вставляет этот ID в ответ, чтобы менеджер мог связать свой запрос с ответом агента.\
Ловушки агент высылает на порт 162 менеджера. Если используется DLTS или TLS, то агент высылает сообщения на порт 10162, а менеджер — на порт 10161. Администратор может изменить порты SNMP, используемые по умолчанию, на любые другие.

[Приручаем железо Lenovo и удивляемся нюансам XClarity](https://habr.com/ru/company/servermall/blog/312408/)

[Как работает VMware DRS](https://habr.com/ru/company/1cloud/blog/268397/)

[Состав сервера Lenovo SR650](https://lenovopress.com/lp0644.pdf)

[Общие принципы аппаратной виртуализации](https://ru.wikipedia.org/wiki/%D0%90%D0%BF%D0%BF%D0%B0%D1%80%D0%B0%D1%82%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B8%D1%80%D1%82%D1%83%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F)

[Lenovo ThinkSystem Firmware and Driver Update Best Practices](https://lenovopress.com/lp0656-lenovo-thinksystem-firmware-and-driver-update-best-practices)

[Набор полезных ссылок от Lenovo по обновлению драйверов и прошивок](https://support.lenovo.com/us/en/solutions/ht103672)

[Как обновлять прошивки через XCC](https://support.lenovo.com/ru/en/solutions/ht507913)

[Lenovo xClarity Controller](https://sysmgt.lenovofiles.com/help/index.jsp?topic=%2Fcom.lenovo.systems.management.xcc.doc%2Fdw1lm_c_ch1_introduction.html)

[Determining Network/Storage firmware and driver version in ESXi](https://kb.vmware.com/s/article/1027206)

[Checking your firmware and BIOS levels to ensure compatibility with ESX/ESXi ](https://kb.vmware.com/s/article/1037257)


Commit changes: 1.1MLC 1.2HLC
